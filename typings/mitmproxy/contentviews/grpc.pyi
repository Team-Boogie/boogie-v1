"""
This type stub file was generated by pyright.
"""

from collections.abc import Generator, Iterable, Iterator
from dataclasses import dataclass
from enum import Enum
from mitmproxy import contentviews, flow, http
from mitmproxy.contentviews import base

class ProtoParser:
    @dataclass
    class ParserRule:
        """
        A parser rule lists Field definitions which are applied if the filter rule matches the flow.

        Matching on flow-level also means, a match applies to request AND response messages.
        To restrict a rule to a requests only use 'ParserRuleRequest', instead.
        To restrict a rule to a responses only use 'ParserRuleResponse', instead.
        """
        field_definitions: list[ProtoParser.ParserFieldDefinition]
        name: str = ...
        filter: str = ...
    
    
    @dataclass
    class ParserRuleResponse(ParserRule):
        """
        A parser rule lists Field definitions which are applied if the filter rule matches the flow.

        The rule only applies if the processed message is a server response.
        """
        ...
    
    
    @dataclass
    class ParserRuleRequest(ParserRule):
        """
        A parser rule lists Field definitions which are applied if the filter rule matches the flow.

        The rule only applies if the processed message is a client request.
        """
        ...
    
    
    @dataclass
    class ParserFieldDefinition:
        """
        Defines how to parse a field (or multiple fields with the same tag) in a protobuf messages.

        This allows to apply an intended decoding (f.e. decode uint64 as double instead) and to assign
        a descriptive name to a field. Field definitions are aggregated into rules, which also holds
        a filter to match selected HTTP messages.

        The most natural way to use this, is to describe known parts of a single protobuf message
        in a set of field descriptors, pack them into a rule and set the filter of the rule in a way,
        that it only applies to proper protobuf messages (f.e. to request traffic against an API endpoint
        matched by an URL flowfilter)
        """
        tag: str
        tag_prefixes: list[str] = ...
        intended_decoding: ProtoParser.DecodedTypes | None = ...
        name: str | None = ...
        as_packed: bool | None = ...
    
    
    @dataclass
    class ParserOptions:
        include_wiretype: bool = ...
        exclude_message_headers: bool = ...
    
    
    class DecodedTypes(Enum):
        int32 = ...
        int64 = ...
        uint32 = ...
        uint64 = ...
        sint32 = ...
        sint64 = ...
        bool = ...
        enum = ...
        fixed32 = ...
        sfixed32 = ...
        float = ...
        fixed64 = ...
        sfixed64 = ...
        double = ...
        string = ...
        bytes = ...
        message = ...
        unknown = ...
    
    
    class WireTypes(Enum):
        varint = ...
        bit_64 = ...
        len_delimited = ...
        group_start = ...
        group_end = ...
        bit_32 = ...
    
    
    @staticmethod
    def read_fields(wire_data: bytes, parent_field: ProtoParser.Field | None, options: ProtoParser.ParserOptions, rules: list[ProtoParser.ParserRule]) -> list[ProtoParser.Field]:
        ...
    
    @staticmethod
    def read_packed_fields(packed_field: ProtoParser.Field) -> list[ProtoParser.Field]:
        ...
    
    class Field:
        """
        Represents a single field of a protobuf message and handles the varios encodings.

        As mitmproxy sees the data passing by as raw protobuf message, it only knows the
        WireTypes. Each of the WireTypes could represent different Protobuf field types.
        The exact Protobuf field type can not be determined from the wire format, thus different
        options for decoding have to be supported.
        In addition the parsed WireTypes are (intermediary) stored in Python types, which adds
        some additional overhead type conversions.

        WireType            represented Protobuf Types                 Python type (intermediary)

        0: varint           int32, int64, uint32, uint64, enum,        int (*)
                            sint32, sint64 (both ZigZag encoded),      int
                            bool                                       bool
                                                                       float (**)

        1: bit_64           fixed64, sfixed64,                         int (*)
                            double                                     float

        2: len_delimited    string,                                    str
                            message,                                   class 'Message'
                            bytes,                                     bytes (*)
                            packed_repeated_field                      class 'Message' (fields with same tag)

        3: group_start      unused (deprecated)                        -
        4: group_end        unused (deprecated)                        -

        5: bit_32           fixed32, sfixed32,                         int (*)
                            float                                      float

        (*) Note 1:  Conversion between WireType and intermediary python representation
                     is handled by Kaitai protobuf decoder and always uses the python
                     representation marked with (*). Converting to alternative representations
                     is handled inside this class.
        (**) Note 2: Varint is not used to represent floating point values, but some applications
                     store native floats in uint32 protobuf types (or native double in uint64).
                     Thus we allow conversion of varint to floating point values for convenience
                     (A well known APIs "hide" GPS latitude and longitude values in varint types,
                     much easier to spot such things when rendered as float)

        Ref: - https://developers.google.com/protocol-buffers/docs/proto3
             - https://developers.google.com/protocol-buffers/docs/encoding
        """
        def __init__(self, wire_type: ProtoParser.WireTypes, preferred_decoding: ProtoParser.DecodedTypes, tag: int, parent_field: ProtoParser.Field | None, wire_value: int | bytes, options: ProtoParser.ParserOptions, rules: list[ProtoParser.ParserRule], is_unpacked_children: bool = ...) -> None:
            ...
        
        def apply_rules(self, only_first_hit=...):
            ...
        
        def safe_decode_as(self, intended_decoding: ProtoParser.DecodedTypes, try_as_packed: bool = ...) -> tuple[ProtoParser.DecodedTypes, bool | float | int | bytes | str | list[ProtoParser.Field],]:
            """
            Tries to decode as intended, applies failover, if not possible

            Returns selected decoding and decoded value
            """
            ...
        
        def decode_as(self, intended_decoding: ProtoParser.DecodedTypes, as_packed: bool = ...) -> bool | int | float | bytes | str | list[ProtoParser.Field]:
            ...
        
        def encode_from(inputval, intended_encoding: ProtoParser.DecodedTypes):
            ...
        
        def wire_value_as_utf8(self, escape_newline=...) -> str:
            ...
        
        def gen_flat_decoded_field_dicts(self) -> Generator[dict, None, None]:
            """
            Returns a generator which passes the field as a dict.

            In order to return the field value it gets decoded (based on a failover strategy and
            provided ParserRules).
            If the field holds a nested message, the fields contained in the message are appended.
            Ultimately this flattens all fields recursively.
            """
            ...
        
    
    
    def __init__(self, data: bytes, rules: list[ProtoParser.ParserRule] | None = ..., parser_options: ParserOptions | None = ...) -> None:
        ...
    
    def gen_flat_decoded_field_dicts(self) -> Generator[dict, None, None]:
        ...
    
    def gen_str_rows(self) -> Generator[tuple[str, ...], None, None]:
        ...
    


def format_table(table_rows: Iterable[tuple[str, ...]], max_col_width=...) -> Iterator[base.TViewLine]:
    """
    Helper function to render tables with variable column count (move to contentview base, if needed elsewhere)

    Note: The function has to convert generators to a list, as all rows have to be processed twice (to determine
    the column widths first).
    """
    ...

def parse_grpc_messages(data, compression_scheme) -> Generator[tuple[bool, bytes], None, None]:
    """Generator iterates over body data and returns a boolean indicating if the messages
    was compressed, along with the raw message data (decompressed) for each gRPC message
    contained in the body data"""
    ...

def hack_generator_to_list(generator_func): # -> list[Unknown]:
    ...

def format_pbuf(message: bytes, parser_options: ProtoParser.ParserOptions, rules: list[ProtoParser.ParserRule]): # -> Generator[TViewLine, Unknown, None]:
    ...

def format_grpc(data: bytes, parser_options: ProtoParser.ParserOptions, rules: list[ProtoParser.ParserRule], compression_scheme=...): # -> Generator[list[tuple[Literal['text'], str]] | TViewLine, Unknown, None]:
    ...

@dataclass
class ViewConfig:
    parser_options: ProtoParser.ParserOptions = ...
    parser_rules: list[ProtoParser.ParserRule] = ...


class ViewGrpcProtobuf(base.View):
    """Human friendly view of protocol buffers"""
    name = ...
    __content_types_pb = ...
    __content_types_grpc = ...
    __valid_grpc_encodings = ...
    def __init__(self, config: ViewConfig | None = ...) -> None:
        ...
    
    def __call__(self, data: bytes, *, content_type: str | None = ..., flow: flow.Flow | None = ..., http_message: http.Message | None = ..., **unknown_metadata) -> contentviews.TViewResult:
        ...
    
    def render_priority(self, data: bytes, *, content_type: str | None = ..., flow: flow.Flow | None = ..., http_message: http.Message | None = ..., **unknown_metadata) -> float:
        ...
    


